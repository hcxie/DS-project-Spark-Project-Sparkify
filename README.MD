[TOC]



# Installation

The required python package includes: numpy, pandas, matplotlib, seaborn, datatime, pyspark

# Project Motivation

This is a capstone Data Science project.

Sparkify is a music streaming service similar to Spotify or Pandora. Each user has the freedom to upgrade their service, downgrade their service or cancel their service. However, when a user cancels his/her service, it means a potential loss in future revenue. The users who cancel their service is called churn user. Sparkify wants to identify the potential churn users, so it makes actions, such as providing a discount, to stop the users from leaving the service. 

Sparkify provided a dataset that records the events generated by users. Every time a user interacted with Sparkify service, no matter whether the user was logging in, playing a song, or check the help page, the interaction was recorded.

Therefore the goal of this project is to develop a model to predict the potential churn user based on user event data using pyspark

# File Description

Sparkify-Capstone-Project- Data Exploration.ipynb - This file demonstrates the data exploration and data visualization procedure using pyspark, matplotlib, seaborn and pandas

Sparkify-Capstone-Project-Feature engineering.ipynb - This file demonstrates the featuring extraction and feature engineering process using pyspark and pandas

Sparkify-Capstone-Project-Model training and validation.ipynb ,Sparkify-Capstone-Project-Model training and validation2.ipynb - This two file show the model training and validation process using pyspark. The dataset used to train the model in first file contains the five categorical feature (gender,level, method, location and user_agent) from original data set. The dataset used in the second one does not. 

temp - This folder contains some drafts I created at initial stage of this project.

# Result

The dataset is imbalanced. The number of normal users is about 4 times larger than churn user.

Three methods were used to handle this issue. First, I augmented the training dataset. After augmentation, the dataset may contain sufficient patterns belonging to the minority class to adequately represent its distribution. Second, I under-sampled the major class by using *sampleBy* in Pyspark to balance the two classes. The third method is to create a balanced training data without reducing the total data size by combing the above two methods.

Three classifier algorithms were used to develop the churn user prediction model: logistic regression, random forest, and gradient-boosted tree regression.

The best performing model is random forest classifier trained by augmented and balanced data. The overall f1 score is 0.8696 and accuracy is 0.86517. The recall for churn user is 0.7895. The precision for churn user is 0.6522. The recall and precision for normal user are 0.8857 and 0.9394.

In addition, time-series based features and session-based features played important roles to improve the model performance. Detailed can be found in this blog: https://medium.com/@jbdx6307/prediction-churn-user-using-pyspark-sparkify-capstone-project-e6852b42dbf7

# Licensing, Authors, Acknowledgements

Author:Haochen X (jbdx6307@gmail.com)

