{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, concat, desc, explode, lit, min, max, split, udf, isnull\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, PCA, RegexTokenizer, StandardScaler, StopWordsRemover, StringIndexer, VectorAssembler\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.read.csv('feature_df.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('cat_gender','cat_level','cat_method','cat_location_state','cat_user_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, count_per_activetime_Submit_Downgrade: string, count_per_activetime_Thumbs_Down: string, count_per_activetime_Home: string, count_per_activetime_Downgrade: string, count_per_activetime_Roll_Advert: string, count_per_activetime_Logout: string, count_per_activetime_Save_Settings: string, count_per_activetime_About: string, count_per_activetime_Settings: string, count_per_activetime_Add_to_Playlist: string, count_per_activetime_Add_Friend: string, count_per_activetime_NextSong: string, count_per_activetime_Thumbs_Up: string, count_per_activetime_Help: string, count_per_activetime_Upgrade: string, count_per_activetime_Error: string, count_per_activetime_Submit_Upgrade: string, weely_page_std_Home: string, weely_page_std_Add_to_Playlist: string, weely_page_std_NextSong: string, weely_page_std_Thumbs_Up: string, daily_page_std_Home: string, daily_page_std_Logout: string, daily_page_std_Add_to_Playlist: string, daily_page_std_NextSong: string, daily_page_std_Thumbs_Up: string, interaction_timelength_Thumbs_Down: string, interaction_timelength_Home: string, interaction_timelength_Roll_Advert: string, interaction_timelength_Logout: string, interaction_timelength_Settings: string, interaction_timelength_Add_to_Playlist: string, interaction_timelength_Add_Friend: string, interaction_timelength_NextSong: string, interaction_timelength_Thumbs_Up: string, interaction_timelength_Help: string, num_uni_songs_per_time: string, num_uni_artists_per_time: string, num_uni_sessions_per_time: string, avg(Thumbs_Down_interaction_per_session): string, avg(Home_interaction_per_session): string, avg(Roll_Advert_interaction_per_session): string, avg(Logout_interaction_per_session): string, avg(Settings_interaction_per_session): string, avg(Add_to_Playlist_interaction_per_session): string, avg(Add_Friend_interaction_per_session): string, avg(NextSong_interaction_per_session): string, avg(Thumbs_Up_interaction_per_session): string, avg(Help_interaction_per_session): string, max(Thumbs_Down_interaction_per_session): string, max(Home_interaction_per_session): string, max(Roll_Advert_interaction_per_session): string, max(Logout_interaction_per_session): string, max(Settings_interaction_per_session): string, max(Add_to_Playlist_interaction_per_session): string, max(Add_Friend_interaction_per_session): string, max(NextSong_interaction_per_session): string, max(Thumbs_Up_interaction_per_session): string, max(Help_interaction_per_session): string, min(Thumbs_Down_interaction_per_session): string, min(Home_interaction_per_session): string, min(Roll_Advert_interaction_per_session): string, min(Logout_interaction_per_session): string, min(Settings_interaction_per_session): string, min(Add_to_Playlist_interaction_per_session): string, min(Add_Friend_interaction_per_session): string, min(NextSong_interaction_per_session): string, min(Thumbs_Up_interaction_per_session): string, min(Help_interaction_per_session): string, avg(sessiontime): string, max(sessiontime): string, min(sessiontime): string, avg_unique_songs_per_session: string, max_unique_songs_per_session_x: string, max_unique_songs_per_session_y: string, Churn: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all string type numerical values to float\n",
    "num_features_list = df.columns[1:]\n",
    "for f in num_features_list:\n",
    "    f_name = f + \"_Num\"\n",
    "    df = df.withColumn(f_name, df[f].cast(\"float\"))\n",
    "    df = df.drop(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, count_per_activetime_Submit_Downgrade_Num: float, count_per_activetime_Thumbs_Down_Num: float, count_per_activetime_Home_Num: float, count_per_activetime_Downgrade_Num: float, count_per_activetime_Roll_Advert_Num: float, count_per_activetime_Logout_Num: float, count_per_activetime_Save_Settings_Num: float, count_per_activetime_About_Num: float, count_per_activetime_Settings_Num: float, count_per_activetime_Add_to_Playlist_Num: float, count_per_activetime_Add_Friend_Num: float, count_per_activetime_NextSong_Num: float, count_per_activetime_Thumbs_Up_Num: float, count_per_activetime_Help_Num: float, count_per_activetime_Upgrade_Num: float, count_per_activetime_Error_Num: float, count_per_activetime_Submit_Upgrade_Num: float, weely_page_std_Home_Num: float, weely_page_std_Add_to_Playlist_Num: float, weely_page_std_NextSong_Num: float, weely_page_std_Thumbs_Up_Num: float, daily_page_std_Home_Num: float, daily_page_std_Logout_Num: float, daily_page_std_Add_to_Playlist_Num: float, daily_page_std_NextSong_Num: float, daily_page_std_Thumbs_Up_Num: float, interaction_timelength_Thumbs_Down_Num: float, interaction_timelength_Home_Num: float, interaction_timelength_Roll_Advert_Num: float, interaction_timelength_Logout_Num: float, interaction_timelength_Settings_Num: float, interaction_timelength_Add_to_Playlist_Num: float, interaction_timelength_Add_Friend_Num: float, interaction_timelength_NextSong_Num: float, interaction_timelength_Thumbs_Up_Num: float, interaction_timelength_Help_Num: float, num_uni_songs_per_time_Num: float, num_uni_artists_per_time_Num: float, num_uni_sessions_per_time_Num: float, avg(Thumbs_Down_interaction_per_session)_Num: float, avg(Home_interaction_per_session)_Num: float, avg(Roll_Advert_interaction_per_session)_Num: float, avg(Logout_interaction_per_session)_Num: float, avg(Settings_interaction_per_session)_Num: float, avg(Add_to_Playlist_interaction_per_session)_Num: float, avg(Add_Friend_interaction_per_session)_Num: float, avg(NextSong_interaction_per_session)_Num: float, avg(Thumbs_Up_interaction_per_session)_Num: float, avg(Help_interaction_per_session)_Num: float, max(Thumbs_Down_interaction_per_session)_Num: float, max(Home_interaction_per_session)_Num: float, max(Roll_Advert_interaction_per_session)_Num: float, max(Logout_interaction_per_session)_Num: float, max(Settings_interaction_per_session)_Num: float, max(Add_to_Playlist_interaction_per_session)_Num: float, max(Add_Friend_interaction_per_session)_Num: float, max(NextSong_interaction_per_session)_Num: float, max(Thumbs_Up_interaction_per_session)_Num: float, max(Help_interaction_per_session)_Num: float, min(Thumbs_Down_interaction_per_session)_Num: float, min(Home_interaction_per_session)_Num: float, min(Roll_Advert_interaction_per_session)_Num: float, min(Logout_interaction_per_session)_Num: float, min(Settings_interaction_per_session)_Num: float, min(Add_to_Playlist_interaction_per_session)_Num: float, min(Add_Friend_interaction_per_session)_Num: float, min(NextSong_interaction_per_session)_Num: float, min(Thumbs_Up_interaction_per_session)_Num: float, min(Help_interaction_per_session)_Num: float, avg(sessiontime)_Num: float, max(sessiontime)_Num: float, min(sessiontime)_Num: float, avg_unique_songs_per_session_Num: float, max_unique_songs_per_session_x_Num: float, max_unique_songs_per_session_y_Num: float, Churn_Num: float]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=df.columns[1:-2], outputCol=\"Features\")\n",
    "data = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"Features\", outputCol=\"StdFeatures\", withStd=True)\n",
    "scalerModel = scaler.fit(data)\n",
    "data = scalerModel.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, count_per_activetime_Submit_Downgrade_Num: float, count_per_activetime_Thumbs_Down_Num: float, count_per_activetime_Home_Num: float, count_per_activetime_Downgrade_Num: float, count_per_activetime_Roll_Advert_Num: float, count_per_activetime_Logout_Num: float, count_per_activetime_Save_Settings_Num: float, count_per_activetime_About_Num: float, count_per_activetime_Settings_Num: float, count_per_activetime_Add_to_Playlist_Num: float, count_per_activetime_Add_Friend_Num: float, count_per_activetime_NextSong_Num: float, count_per_activetime_Thumbs_Up_Num: float, count_per_activetime_Help_Num: float, count_per_activetime_Upgrade_Num: float, count_per_activetime_Error_Num: float, count_per_activetime_Submit_Upgrade_Num: float, weely_page_std_Home_Num: float, weely_page_std_Add_to_Playlist_Num: float, weely_page_std_NextSong_Num: float, weely_page_std_Thumbs_Up_Num: float, daily_page_std_Home_Num: float, daily_page_std_Logout_Num: float, daily_page_std_Add_to_Playlist_Num: float, daily_page_std_NextSong_Num: float, daily_page_std_Thumbs_Up_Num: float, interaction_timelength_Thumbs_Down_Num: float, interaction_timelength_Home_Num: float, interaction_timelength_Roll_Advert_Num: float, interaction_timelength_Logout_Num: float, interaction_timelength_Settings_Num: float, interaction_timelength_Add_to_Playlist_Num: float, interaction_timelength_Add_Friend_Num: float, interaction_timelength_NextSong_Num: float, interaction_timelength_Thumbs_Up_Num: float, interaction_timelength_Help_Num: float, num_uni_songs_per_time_Num: float, num_uni_artists_per_time_Num: float, num_uni_sessions_per_time_Num: float, avg(Thumbs_Down_interaction_per_session)_Num: float, avg(Home_interaction_per_session)_Num: float, avg(Roll_Advert_interaction_per_session)_Num: float, avg(Logout_interaction_per_session)_Num: float, avg(Settings_interaction_per_session)_Num: float, avg(Add_to_Playlist_interaction_per_session)_Num: float, avg(Add_Friend_interaction_per_session)_Num: float, avg(NextSong_interaction_per_session)_Num: float, avg(Thumbs_Up_interaction_per_session)_Num: float, avg(Help_interaction_per_session)_Num: float, max(Thumbs_Down_interaction_per_session)_Num: float, max(Home_interaction_per_session)_Num: float, max(Roll_Advert_interaction_per_session)_Num: float, max(Logout_interaction_per_session)_Num: float, max(Settings_interaction_per_session)_Num: float, max(Add_to_Playlist_interaction_per_session)_Num: float, max(Add_Friend_interaction_per_session)_Num: float, max(NextSong_interaction_per_session)_Num: float, max(Thumbs_Up_interaction_per_session)_Num: float, max(Help_interaction_per_session)_Num: float, min(Thumbs_Down_interaction_per_session)_Num: float, min(Home_interaction_per_session)_Num: float, min(Roll_Advert_interaction_per_session)_Num: float, min(Logout_interaction_per_session)_Num: float, min(Settings_interaction_per_session)_Num: float, min(Add_to_Playlist_interaction_per_session)_Num: float, min(Add_Friend_interaction_per_session)_Num: float, min(NextSong_interaction_per_session)_Num: float, min(Thumbs_Up_interaction_per_session)_Num: float, min(Help_interaction_per_session)_Num: float, avg(sessiontime)_Num: float, max(sessiontime)_Num: float, min(sessiontime)_Num: float, avg_unique_songs_per_session_Num: float, max_unique_songs_per_session_x_Num: float, max_unique_songs_per_session_y_Num: float, Churn_Num: float, Features: vector, StdFeatures: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1d9dd6710>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(k=70, inputCol=\"StdFeatures\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(data)\n",
    "\n",
    "ind=np.arange(70)\n",
    "val=np.array(model.explainedVariance)\n",
    "cumvals=np.cumsum(val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(ind, val)\n",
    "ax.plot(ind,cumvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "k=len(val[val>0.01])\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "k=len(val[val>0.005])\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca17 = PCA(k=20, inputCol=\"StdFeatures\", outputCol=\"pcaFeatures\")\n",
    "model17 = pca17.fit(data)\n",
    "data17 = model17.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca76 = PCA(k=30, inputCol=\"StdFeatures\", outputCol=\"pcaFeatures\")\n",
    "model76 = pca76.fit(data)\n",
    "data76 = model76.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 17 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|   99|\n",
      "|  0.0|  349|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_churn = data17.select(data17.Churn_Num.alias(\"label\"), data17.pcaFeatures.alias(\"features\"))\n",
    "data_churn.select('label').groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = data_churn.randomSplit([0.8, 0.2], seed=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  handle unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|  150|\n",
      "|  0.0|  566|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|   80|\n",
      "|  0.0|   89|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|  150|\n",
      "|  0.0|  173|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# method 1, Augmentation\n",
    "oversampled_train=train.sample(True, 2.0, 110)\n",
    "oversampled_train.select('label').groupby('label').count().show()\n",
    "# method 2, under sample the popular class\n",
    "stratified_train = train.sampleBy('label', fractions={0: 0.3, 1: 1.0}).cache()\n",
    "stratified_train.select('label').groupby('label').count().show()\n",
    "# method 3,Augmentation then under sample the popular class\n",
    "stratified_train2 = oversampled_train.sampleBy('label', fractions={0: 0.3, 1: 1.0}).cache()\n",
    "stratified_train2.select('label').groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation metrics\n",
    "def evaluate_result(results,model_name):\n",
    "    \"\"\"\n",
    "    This function print out the f1 score, accuracy, recall and precision from prediction result \n",
    "    input: results - a pyspark data frame containing the predicted result\n",
    "           model_name - a string that contains the model's name\n",
    "    output: None\n",
    "    \"\"\"\n",
    "    print(model_name,\" f1 score: \", MulticlassClassificationEvaluator(metricName=\"f1\").evaluate(results))\n",
    "    print(model_name,\" accuracy: \", MulticlassClassificationEvaluator(metricName=\"accuracy\").evaluate(results))\n",
    "    rdd=results.select('label','prediction').rdd.map(lambda line: (line[1], line[0]))\n",
    "    metrics = MulticlassMetrics(rdd)\n",
    "    print(\"label 1 recall: \", metrics.recall(1),\", precision: \",metrics.precision(1))\n",
    "    print(\"label 0 recall: \", metrics.recall(0),\", precision: \",metrics.precision(0))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_modelcomparison(train,validation):\n",
    "    \"\"\"\n",
    "    This function will trained a logistic regreession,a  random forest and a gradient boost tree using training data and evaluate model's performance using validation data.\n",
    "    input: train - training data set\n",
    "           validation - validation dataset\n",
    "    output: cvModel_lr - best trained logistic regression model\n",
    "            cvModel_rf - best trained random forest model\n",
    "            cvModel_gbts - best trained gradient boost tree model\n",
    "    \n",
    "    \"\"\"\n",
    "    lr =  LogisticRegression(featuresCol = 'features', labelCol = 'label')\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(lr.elasticNetParam,[0.0, 0.1, 0.2]) \\\n",
    "        .addGrid(lr.regParam,[0.0, 0.1, 0.2, 0.3]) \\\n",
    "        .addGrid(lr.maxIter,[5, 10, 15, 20, 25]) \\\n",
    "        .build()\n",
    "\n",
    "    crossval_lr = CrossValidator(estimator=lr,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(metricName=\"f1\"),\n",
    "                              numFolds=10)\n",
    "    cvModel_lr = crossval_lr.fit(train)\n",
    "    lr_avgMetrics=cvModel_lr.avgMetrics\n",
    "    results_lr = cvModel_lr.transform(validation)\n",
    "    evaluate_result(results_lr,\"logistic regression\")\n",
    "    #--------------------------------------------------------\n",
    "    rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label',)\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(rf.impurity,['entropy','gini']) \\\n",
    "        .addGrid(rf.maxDepth,[10, 15, 20, 25]) \\\n",
    "        .addGrid(rf.numTrees,[20, 30, 40]) \\\n",
    "        .build()\n",
    "    crossval_rf = CrossValidator(estimator=rf,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(metricName=\"f1\"),\n",
    "                              numFolds=10)\n",
    "    cvModel_rf= crossval_rf.fit(train)\n",
    "    rf_avgMetrics = cvModel_rf.avgMetrics\n",
    "    results_rf = cvModel_rf.transform(validation)\n",
    "    evaluate_result(results_rf,\"random forest\")\n",
    "    #-----------------------------------------------------------\n",
    "    gbts = GBTClassifier()\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(gbts.maxIter,[20, 30, 40]) \\\n",
    "        .addGrid(gbts.maxDepth,[2, 4, 6, 8]) \\\n",
    "        .build()\n",
    "    crossval_gbts = CrossValidator(estimator=gbts,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(metricName=\"f1\"),\n",
    "                              numFolds=10)\n",
    "    cvModel_gbts = crossval_gbts.fit(train)\n",
    "    gbts_avgMetrics = cvModel_gbts.avgMetrics\n",
    "    results_gbts = cvModel_gbts.transform(validation)\n",
    "    evaluate_result(results_gbts,\"GBT\")\n",
    "    return cvModel_lr,cvModel_rf,cvModel_gbts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression  f1 score:  0.869172155495286\n",
      "logistic regression  accuracy:  0.8764044943820225\n",
      "label 1 recall:  0.5789473684210527 , precision:  0.7857142857142857\n",
      "label 0 recall:  0.9571428571428572 , precision:  0.8933333333333333\n",
      "random forest  f1 score:  0.7948006168759638\n",
      "random forest  accuracy:  0.8314606741573034\n",
      "label 1 recall:  0.2631578947368421 , precision:  0.8333333333333334\n",
      "label 0 recall:  0.9857142857142858 , precision:  0.8313253012048193\n",
      "GBT  f1 score:  0.8164969844032987\n",
      "GBT  accuracy:  0.8202247191011236\n",
      "label 1 recall:  0.5263157894736842 , precision:  0.5882352941176471\n",
      "label 0 recall:  0.9 , precision:  0.875\n"
     ]
    }
   ],
   "source": [
    "lr_model1,rf_model1,gbts_model1=three_modelcomparison(oversampled_train,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression  f1 score:  0.8330151781772508\n",
      "logistic regression  accuracy:  0.8314606741573034\n",
      "label 1 recall:  0.631578947368421 , precision:  0.6\n",
      "label 0 recall:  0.8857142857142857 , precision:  0.8985507246376812\n",
      "random forest  f1 score:  0.8110414866032843\n",
      "random forest  accuracy:  0.797752808988764\n",
      "label 1 recall:  0.7894736842105263 , precision:  0.5172413793103449\n",
      "label 0 recall:  0.8 , precision:  0.9333333333333333\n",
      "GBT  f1 score:  0.762637269450922\n",
      "GBT  accuracy:  0.7415730337078652\n",
      "label 1 recall:  0.7894736842105263 , precision:  0.4411764705882353\n",
      "label 0 recall:  0.7285714285714285 , precision:  0.9272727272727272\n"
     ]
    }
   ],
   "source": [
    "lr_model2,rf_model2,gbts_model2=three_modelcomparison(stratified_train,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression  f1 score:  0.8284573048953394\n",
      "logistic regression  accuracy:  0.8202247191011236\n",
      "label 1 recall:  0.7368421052631579 , precision:  0.56\n",
      "label 0 recall:  0.8428571428571429 , precision:  0.921875\n",
      "random forest  f1 score:  0.8696062694740817\n",
      "random forest  accuracy:  0.8651685393258427\n",
      "label 1 recall:  0.7894736842105263 , precision:  0.6521739130434783\n",
      "label 0 recall:  0.8857142857142857 , precision:  0.9393939393939394\n",
      "GBT  f1 score:  0.7785310590120316\n",
      "GBT  accuracy:  0.7640449438202247\n",
      "label 1 recall:  0.6842105263157895 , precision:  0.4642857142857143\n",
      "label 0 recall:  0.7857142857142857 , precision:  0.9016393442622951\n"
     ]
    }
   ],
   "source": [
    "lr_model3,rf_model3,gbts_model3=three_modelcomparison(stratified_train2,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 76 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|   99|\n",
      "|  0.0|  349|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|  150|\n",
      "|  0.0|  566|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|   80|\n",
      "|  0.0|   80|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0|  150|\n",
      "|  0.0|  171|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_churn = data76.select(data76.Churn_Num.alias(\"label\"), data76.pcaFeatures.alias(\"features\"))\n",
    "data_churn.select('label').groupby('label').count().show()\n",
    "\n",
    "train, validation = data_churn.randomSplit([0.8, 0.2], seed=110)\n",
    "\n",
    "# method 1, Augmentation\n",
    "oversampled_train=train.sample(True, 2.0, 110)\n",
    "oversampled_train.select('label').groupby('label').count().show()\n",
    "# method 2, under sample the popular class\n",
    "stratified_train = train.sampleBy('label', fractions={0: 0.3, 1: 1.0}).cache()\n",
    "stratified_train.select('label').groupby('label').count().show()\n",
    "# method 3,Augmentation then under sample the popular class\n",
    "stratified_train2 = oversampled_train.sampleBy('label', fractions={0: 0.3, 1: 1.0}).cache()\n",
    "stratified_train2.select('label').groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression  f1 score:  0.8724040004938881\n",
      "logistic regression  accuracy:  0.8764044943820225\n",
      "label 1 recall:  0.631578947368421 , precision:  0.75\n",
      "label 0 recall:  0.9428571428571428 , precision:  0.9041095890410958\n",
      "random forest  f1 score:  0.8294984470295134\n",
      "random forest  accuracy:  0.8539325842696629\n",
      "label 1 recall:  0.3684210526315789 , precision:  0.875\n",
      "label 0 recall:  0.9857142857142858 , precision:  0.8518518518518519\n",
      "GBT  f1 score:  0.857677235839036\n",
      "GBT  accuracy:  0.8539325842696629\n",
      "label 1 recall:  0.7368421052631579 , precision:  0.6363636363636364\n",
      "label 0 recall:  0.8857142857142857 , precision:  0.9253731343283582\n"
     ]
    }
   ],
   "source": [
    "lr76_model1,rf76_model1,gbts76_model1=three_modelcomparison(oversampled_train,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression  f1 score:  0.8013772532791532\n",
      "logistic regression  accuracy:  0.7865168539325843\n",
      "label 1 recall:  0.7894736842105263 , precision:  0.5\n",
      "label 0 recall:  0.7857142857142857 , precision:  0.9322033898305084\n",
      "random forest  f1 score:  0.7820412071756067\n",
      "random forest  accuracy:  0.7640449438202247\n",
      "label 1 recall:  0.7894736842105263 , precision:  0.46875\n",
      "label 0 recall:  0.7571428571428571 , precision:  0.9298245614035088\n",
      "GBT  f1 score:  0.8304096164379505\n",
      "GBT  accuracy:  0.8202247191011236\n",
      "label 1 recall:  0.7894736842105263 , precision:  0.5555555555555556\n",
      "label 0 recall:  0.8285714285714286 , precision:  0.9354838709677419\n"
     ]
    }
   ],
   "source": [
    "lr76_model2,rf76_model2,gbts76_model2=three_modelcomparison(stratified_train,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression  f1 score:  0.8070144680072568\n",
      "logistic regression  accuracy:  0.797752808988764\n",
      "label 1 recall:  0.6842105263157895 , precision:  0.52\n",
      "label 0 recall:  0.8285714285714286 , precision:  0.90625\n",
      "random forest  f1 score:  0.8651685393258427\n",
      "random forest  accuracy:  0.8651685393258427\n",
      "label 1 recall:  0.6842105263157895 , precision:  0.6842105263157895\n",
      "label 0 recall:  0.9142857142857143 , precision:  0.9142857142857143\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1317769.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 457647.0 failed 1 times, most recent failure: Lost task 0.0 in stage 457647.0 (TID 459175, localhost, executor driver): java.io.FileNotFoundException: File file:/G:/operation d/DS-project-Spark-Project-Sparkify/feature_df.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:370)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:370)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:369)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1214)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1214)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.countByValue(RDD.scala:1213)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.labelCountByClass$lzycompute(MulticlassMetrics.scala:42)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.labelCountByClass(MulticlassMetrics.scala:42)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.weightedFMeasure$lzycompute(MulticlassMetrics.scala:215)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.weightedFMeasure(MulticlassMetrics.scala:215)\r\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:84)\r\n\tat sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.io.FileNotFoundException: File file:/G:/operation d/DS-project-Spark-Project-Sparkify/feature_df.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-111c39ce1573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr76_model3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf76_model3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgbts76_model3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthree_modelcomparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstratified_train2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-9f90ed1b7aac>\u001b[0m in \u001b[0;36mthree_modelcomparison\u001b[1;34m(train, validation)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mgbts_avgMetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvModel_gbts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgMetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mresults_gbts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvModel_gbts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mevaluate_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_gbts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"GBT\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcvModel_lr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcvModel_rf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcvModel_gbts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-d8b2a524d5c8>\u001b[0m in \u001b[0;36mevaluate_result\u001b[1;34m(results, model_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define the evaluation metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" f1 score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrdd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\xbxb\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\xbxb\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \"\"\"\n\u001b[0;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\xbxb\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\xbxb\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\xbxb\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1317769.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 457647.0 failed 1 times, most recent failure: Lost task 0.0 in stage 457647.0 (TID 459175, localhost, executor driver): java.io.FileNotFoundException: File file:/G:/operation d/DS-project-Spark-Project-Sparkify/feature_df.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:370)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:370)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:369)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1214)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1214)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.countByValue(RDD.scala:1213)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.labelCountByClass$lzycompute(MulticlassMetrics.scala:42)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.labelCountByClass(MulticlassMetrics.scala:42)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.weightedFMeasure$lzycompute(MulticlassMetrics.scala:215)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.weightedFMeasure(MulticlassMetrics.scala:215)\r\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:84)\r\n\tat sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.io.FileNotFoundException: File file:/G:/operation d/DS-project-Spark-Project-Sparkify/feature_df.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "lr76_model3,rf76_model3,gbts76_model3=three_modelcomparison(stratified_train2,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
