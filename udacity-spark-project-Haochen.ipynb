{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Sparkify Capstone Porject workspace for full data set(12GB)"}, {"metadata": {}, "cell_type": "markdown", "source": "import library"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import pyspark\nfrom pyspark import SparkConf\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import avg, col, concat, desc, explode, lit, min, max, split, udf, isnull\nfrom pyspark.ml.feature import OneHotEncoderEstimator\nfrom pyspark.ml.feature import CountVectorizer, IDF, Normalizer, PCA, RegexTokenizer, StandardScaler, StopWordsRemover, StringIndexer, VectorAssembler\nimport datetime\n\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, NaiveBayes\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "312f0398dd974bc496816d2ff704e795"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1555988898012_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-24-192.us-east-2.compute.internal:20888/proxy/application_1555988898012_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-20-207.us-east-2.compute.internal:8042/node/containerlogs/container_1555988898012_0003_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## ETL "}, {"metadata": {}, "cell_type": "markdown", "source": "### Extract data\nload data"}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "# Create spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Sparkify\") \\\n    .getOrCreate()\n\n# Read in full sparkify dataset\nevent_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "055db816d34c4f33af40b9f100026bda"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark_df = spark.read.json(event_data)\n", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9c49d13ddb464ba3a961c06bccc9278e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark_df.count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### clean null and empty data"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark_df_clean=spark_df.filter(spark_df[\"userId\"]!=\"\")\nspark_df_clean=spark_df_clean.dropna(how=\"any\",subset=[\"userId\",'sessionId'])", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ec6a3c55f1d248afbb3066fa0f53622e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark_df_clean.count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Transformation"}, {"metadata": {}, "cell_type": "markdown", "source": "#### convert ts to real time"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "gen_time = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).strftime(\"%Y-%m-%d %H:%M:%S\"))\nspark_df_clean = spark_df_clean.withColumn(\"time\", gen_time(spark_df_clean['ts']))", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "af83a39fdedf4f469c45d2ef6ac7c646"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "get hour, weekday and day"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "gen_hour = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).hour)\nspark_df_clean = spark_df_clean.withColumn(\"hour\", gen_hour(spark_df_clean['ts']))\n\ngen_weekday = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).strftime(\"%w\"))\nspark_df_clean = spark_df_clean.withColumn(\"weekday\", gen_weekday(spark_df_clean['ts']))\n\ngen_day = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).day)\nspark_df_clean = spark_df_clean.withColumn(\"day\", gen_day(spark_df_clean['ts']))", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7bdecfb77f88445699284b5f49a005aa"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### convert location to state"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "get_state=udf(lambda x:x[-2:])\nspark_df_clean = spark_df_clean.withColumn(\"location_state\", get_state(spark_df_clean['location']))", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "1a04c5fba87a41bf8585478a853abce4"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### simplify userAgent"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "simp_useragent=udf(lambda x:\"\".join(x[x.index('(')+1:x.index(')')]))\nspark_df_clean= spark_df_clean.withColumn(\"sim_user_agent\", simp_useragent(spark_df_clean['userAgent']))", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ca1884b347cc4b6091ca36905b14c6dc"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Feature engineering"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def features_merge(df1, df2):\n    \"\"\"\n    This function is used to merge the feature using left join\n    input: two data frame to be merged\n    output: merged dataframe\n    \"\"\"\n    df2 = df2.withColumnRenamed(\"userId\", \"userIdTemp\")\n    df = df1.join(df2, df1.userId == df2.userIdTemp, \"left\").drop(\"userIdTemp\")\n    return df", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d91e0d6fd25d493783f3e98337e975a2"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# user_list\ndf_feature=spark_df_clean.select('userId').dropDuplicates().sort('userId')", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "570b995f402247248cc50f08584218ba"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "user_list = [(row['userId']) for row in spark_df_clean.select(\"userId\").dropDuplicates().sort('userId').collect()]", "execution_count": 21, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0756a0e9eeb64e0bbe5ce8609d149862"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# gender\ngender_df=spark_df_clean.select('userId','gender').dropDuplicates().sort('userId')\ndf_feature=features_merge(df_feature,gender_df)", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a00b1db3e15949d1bc370f92ad93b9e5"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# level\nlevel_df=spark_df_clean.select('userId','level').dropDuplicates().sort('userId')\ndf_feature=features_merge(df_feature,level_df)", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a96213ee43714ec38245ce26dbce19f8"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# method\nmethod_df=spark_df_clean.select('userId','method').dropDuplicates().sort('userId')\ndf_feature=features_merge(df_feature,method_df)", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "db0448cb748c467590a6d8f636da92a9"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# location_state\nlocation_state_df=spark_df_clean.select('userId','location_state').dropDuplicates().sort('userId')\ndf_feature=features_merge(df_feature,location_state_df)", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2592b8c0155448f996f7d70d82221b2e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# user agent\nagent_df=spark_df_clean.select('userId','sim_user_agent').dropDuplicates().sort('userId')\ndf_feature=features_merge(df_feature,agent_df)", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "93aaddbb78ba4fe6b6ea2231d8ca49bd"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#get count usage of each page type\npage_list = [(row['page']) for row in spark_df_clean.select(\"page\").dropDuplicates().collect()]", "execution_count": null, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5cd13f036ac9477bb2d4dbfb7dbe358a"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "temp_df_feature=spark_df_clean.select('userId').dropDuplicates().sort('userId')\nfor page in page_list:\n    col_name = \"count\" + page.replace(\" \", \"\")\n    temp_page_count=spark_df_clean.filter(spark_df_clean['page']==page).groupby(\"userId\").count().sort('userId')\n    temp_page_count=temp_page_count.withColumnRenamed(\"count\",col_name)\n    temp_df_feature=features_merge(temp_df_feature,temp_page_count)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "page_view_total_count=spark_df_clean.groupby(\"userId\").count().sort('userId')\n\nfrequency_df_feature=temp_df_feature.select('id').subtract(df_b.select('id'))", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}